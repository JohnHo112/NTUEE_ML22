{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a name=\"top\"></a>\n# **HW15 Meta Learning: Few-shot Classification**\n\nThis is the sample code for homework 15.\n\nPlease mail to mlta-2023-spring@googlegroups.com if you have any questions.","metadata":{"id":"FMNkUejzNFrQ"}},{"cell_type":"markdown","source":"## **Step 0: Check GPU**","metadata":{"id":"RdpzIMG6XsGK"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"zjjHsZbaL7SV","execution":{"iopub.status.busy":"2023-06-24T09:37:38.962820Z","iopub.execute_input":"2023-06-24T09:37:38.964966Z","iopub.status.idle":"2023-06-24T09:37:40.313191Z","shell.execute_reply.started":"2023-06-24T09:37:38.964930Z","shell.execute_reply":"2023-06-24T09:37:40.311950Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Sat Jun 24 09:37:40 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   30C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Step 1: Download Data**\n\nRun the cell to download data, which has been pre-processed by TAs.  \nThe dataset has been augmented, so extra data augmentation is not required.\n","metadata":{"id":"bQ3wvyjnXwGX"}},{"cell_type":"code","source":"workspace_dir = '.'\n\n# Download dataset\n!wget https://www.dropbox.com/s/pqeym3n4jly5e89/Omniglot.tar.gz?dl=1 \\\n    -O \"{workspace_dir}/Omniglot.tar.gz\"\n!wget https://www.dropbox.com/s/nlvokertmksfc42/Omniglot-test.tar.gz?dl=1 \\\n    -O \"{workspace_dir}/Omniglot-test.tar.gz\"\n\n# Use `tar' command to decompress\n!tar -zxf \"{workspace_dir}/Omniglot.tar.gz\" -C \"{workspace_dir}/\"\n!tar -zxf \"{workspace_dir}/Omniglot-test.tar.gz\" -C \"{workspace_dir}/\"","metadata":{"id":"g7Gt4Jucug41","execution":{"iopub.status.busy":"2023-06-24T09:37:40.318900Z","iopub.execute_input":"2023-06-24T09:37:40.319259Z","iopub.status.idle":"2023-06-24T09:37:52.454261Z","shell.execute_reply.started":"2023-06-24T09:37:40.319226Z","shell.execute_reply":"2023-06-24T09:37:52.452973Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-06-24 09:37:41--  https://www.dropbox.com/s/pqeym3n4jly5e89/Omniglot.tar.gz?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.83.18, 2620:100:6033:18::a27d:5312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.83.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/dl/pqeym3n4jly5e89/Omniglot.tar.gz [following]\n--2023-06-24 09:37:42--  https://www.dropbox.com/s/dl/pqeym3n4jly5e89/Omniglot.tar.gz\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com/cd/0/get/B-lxGu1ymaivAE9KR2kaUDU_OMXZMStC5hWqqaKPrkK-63Zil-tPpYQIh_Zoa7_1VjSX3j1DQoR-PhsrqmDYFJTHkTto7pwGPIDIo9Xx9-RdgZj8Q1sYBAZq1HHtcZSbtc803CPHVMcOnTFFx30ug1okaMzrdCa_BD2uVX118pdWLP8qBafbO3AvhIKck4JPMGs/file?dl=1# [following]\n--2023-06-24 09:37:42--  https://uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com/cd/0/get/B-lxGu1ymaivAE9KR2kaUDU_OMXZMStC5hWqqaKPrkK-63Zil-tPpYQIh_Zoa7_1VjSX3j1DQoR-PhsrqmDYFJTHkTto7pwGPIDIo9Xx9-RdgZj8Q1sYBAZq1HHtcZSbtc803CPHVMcOnTFFx30ug1okaMzrdCa_BD2uVX118pdWLP8qBafbO3AvhIKck4JPMGs/file?dl=1\nResolving uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com (uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com)... 162.125.83.15, 2620:100:6033:15::a27d:530f\nConnecting to uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com (uc02e16c6a1bfca0c97c74b5deb5.dl.dropboxusercontent.com)|162.125.83.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5718170 (5.5M) [application/binary]\nSaving to: ‘./Omniglot.tar.gz’\n\n./Omniglot.tar.gz   100%[===================>]   5.45M  4.93MB/s    in 1.1s    \n\n2023-06-24 09:37:44 (4.93 MB/s) - ‘./Omniglot.tar.gz’ saved [5718170/5718170]\n\n--2023-06-24 09:37:45--  https://www.dropbox.com/s/nlvokertmksfc42/Omniglot-test.tar.gz?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.83.18, 2620:100:6033:18::a27d:5312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.83.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/dl/nlvokertmksfc42/Omniglot-test.tar.gz [following]\n--2023-06-24 09:37:46--  https://www.dropbox.com/s/dl/nlvokertmksfc42/Omniglot-test.tar.gz\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com/cd/0/get/B-kwGLEXhFicAe1wb_hGG_h0SHlNdIwRawMcbvQKsFhomxtQzbZUrUCkrmkUTlx2KqP8puOvqRjgUWHUY2yOgV_TZ5JF9y7gS9zpS8G-_S4TfvIAlhLHhIsZ0G2oTIdZb5ya2jFLtIFT27pJOGBiX0Kp9FQwke2uQnSf7WlgLB-hvd9-RJAQo4t9GklA0WewC3M/file?dl=1# [following]\n--2023-06-24 09:37:47--  https://uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com/cd/0/get/B-kwGLEXhFicAe1wb_hGG_h0SHlNdIwRawMcbvQKsFhomxtQzbZUrUCkrmkUTlx2KqP8puOvqRjgUWHUY2yOgV_TZ5JF9y7gS9zpS8G-_S4TfvIAlhLHhIsZ0G2oTIdZb5ya2jFLtIFT27pJOGBiX0Kp9FQwke2uQnSf7WlgLB-hvd9-RJAQo4t9GklA0WewC3M/file?dl=1\nResolving uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com (uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com)... 162.125.83.15, 2620:100:6033:15::a27d:530f\nConnecting to uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com (uc5039cb65445c08606fe9fbe737.dl.dropboxusercontent.com)|162.125.83.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1822122 (1.7M) [application/binary]\nSaving to: ‘./Omniglot-test.tar.gz’\n\n./Omniglot-test.tar 100%[===================>]   1.74M  2.82MB/s    in 0.6s    \n\n2023-06-24 09:37:48 (2.82 MB/s) - ‘./Omniglot-test.tar.gz’ saved [1822122/1822122]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Step 2: Build the model**","metadata":{"id":"baVsWfcSYHVN"}},{"cell_type":"markdown","source":"### Library importation","metadata":{"id":"gqiOdDLgYOlQ"}},{"cell_type":"code","source":"# Import modules we need\nimport glob, random\nfrom collections import OrderedDict\n\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nimport torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\nfrom IPython.display import display\n\n# Check device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"DEVICE = {device}\")\n\n# Fix random seeds\nrandom_seed = 0\nrandom.seed(random_seed)\nnp.random.seed(random_seed)\ntorch.manual_seed(random_seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(random_seed)","metadata":{"id":"-9pfkqh8gxHD","execution":{"iopub.status.busy":"2023-06-24T09:37:52.456378Z","iopub.execute_input":"2023-06-24T09:37:52.456764Z","iopub.status.idle":"2023-06-24T09:37:55.636582Z","shell.execute_reply.started":"2023-06-24T09:37:52.456709Z","shell.execute_reply":"2023-06-24T09:37:55.635532Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DEVICE = cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Construction Preliminaries\n\nSince our task is image classification, we need to build a CNN-based model.  \nHowever, to implement MAML algorithm, we should adjust some code in `nn.Module`.\n","metadata":{"id":"3TlwLtC1YRT7"}},{"cell_type":"markdown","source":"Take a look at MAML pseudocode...\n\n<img src=\"https://i.imgur.com/9aHlvfX.png\" width=\"50%\" />\n\nOn the 10-th line, what we take gradients on are those $\\theta$ representing  \n<font color=\"#0CC\">**the original model parameters**</font> (outer loop) instead of those in  the  \n<font color=\"#0C0\">**inner loop**</font>, so we need to use `functional_forward` to compute the output  \nlogits of input image instead of `forward` in `nn.Module`.\n\nThe following defines these functions.\n\n<!-- 由於在第10行，我們是要對原本的參數 θ 微分，並非 inner-loop (Line5~8) 的 θ' 微分，因此在 inner-loop，我們需要用 functional forward 的方式算出 input image 的 output logits，而不是直接用 nn.module 裡面的 forward（直接對 θ 微分）。在下面我們分別定義了 functional forward 以及 forward 函數。 -->","metadata":{"id":"dFwB3tuEDYfy"}},{"cell_type":"markdown","source":"### Model block definition","metadata":{"id":"iuYQiPeQYc__"}},{"cell_type":"code","source":"def ConvBlock(in_ch: int, out_ch: int):\n    return nn.Sequential(\n        nn.Conv2d(in_ch, out_ch, 3, padding=1),\n        nn.BatchNorm2d(out_ch),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n    )\n\n\ndef ConvBlockFunction(x, w, b, w_bn, b_bn):\n    x = F.conv2d(x, w, b, padding=1)\n    x = F.batch_norm(\n        x, running_mean=None, running_var=None, weight=w_bn, bias=b_bn, training=True\n    )\n    x = F.relu(x)\n    x = F.max_pool2d(x, kernel_size=2, stride=2)\n    return x","metadata":{"id":"GgFbbKHYg3Hk","execution":{"iopub.status.busy":"2023-06-24T09:37:55.639362Z","iopub.execute_input":"2023-06-24T09:37:55.640301Z","iopub.status.idle":"2023-06-24T09:37:55.647970Z","shell.execute_reply.started":"2023-06-24T09:37:55.640253Z","shell.execute_reply":"2023-06-24T09:37:55.646598Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Model definition","metadata":{"id":"iQEzgWN7fi7B"}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, in_ch, k_way):\n        super(Classifier, self).__init__()\n        self.conv1 = ConvBlock(in_ch, 64)\n        self.conv2 = ConvBlock(64, 64)\n        self.conv3 = ConvBlock(64, 64)\n        self.conv4 = ConvBlock(64, 64)\n        self.logits = nn.Linear(64, k_way)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = x.view(x.shape[0], -1)\n        x = self.logits(x)\n        return x\n\n    def functional_forward(self, x, params):\n        \"\"\"\n        Arguments:\n        x: input images [batch, 1, 28, 28]\n        params: model parameters,\n                i.e. weights and biases of convolution\n                     and weights and biases of\n                                   batch normalization\n                type is an OrderedDict\n\n        Arguments:\n        x: input images [batch, 1, 28, 28]\n        params: The model parameters,\n                i.e. weights and biases of convolution\n                     and batch normalization layers\n                It's an `OrderedDict`\n        \"\"\"\n        for block in [1, 2, 3, 4]:\n            x = ConvBlockFunction(\n                x,\n                params[f\"conv{block}.0.weight\"],\n                params[f\"conv{block}.0.bias\"],\n                params.get(f\"conv{block}.1.weight\"),\n                params.get(f\"conv{block}.1.bias\"),\n            )\n        x = x.view(x.shape[0], -1)\n        x = F.linear(x, params[\"logits.weight\"], params[\"logits.bias\"])\n        return x","metadata":{"id":"0bFBGEQoHQUW","execution":{"iopub.status.busy":"2023-06-24T09:37:55.649640Z","iopub.execute_input":"2023-06-24T09:37:55.651559Z","iopub.status.idle":"2023-06-24T09:37:55.664610Z","shell.execute_reply.started":"2023-06-24T09:37:55.651531Z","shell.execute_reply":"2023-06-24T09:37:55.663527Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Create Label\n\nThis function is used to create labels.  \nIn a N-way K-shot few-shot classification problem,\neach task has `n_way` classes, while there are `k_shot` images for each class.  \nThis is a function that creates such labels.\n","metadata":{"id":"gmJq_0B9Yj0G"}},{"cell_type":"code","source":"def create_label(n_way, k_shot):\n    return torch.arange(n_way).repeat_interleave(k_shot).long()\n\n\n# Try to create labels for 5-way 2-shot setting\ncreate_label(5, 2)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQF5vgLvg5aX","outputId":"25658cf3-4604-452c-f590-6626be9d7a07","execution":{"iopub.status.busy":"2023-06-24T09:37:55.665867Z","iopub.execute_input":"2023-06-24T09:37:55.666168Z","iopub.status.idle":"2023-06-24T09:37:55.736177Z","shell.execute_reply.started":"2023-06-24T09:37:55.666142Z","shell.execute_reply":"2023-06-24T09:37:55.735045Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Accuracy calculation","metadata":{"id":"2nCFv9PGw50J"}},{"cell_type":"code","source":"def calculate_accuracy(logits, labels):\n    \"\"\"utility function for accuracy calculation\"\"\"\n    acc = np.asarray(\n        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n    ).mean()\n    return acc","metadata":{"id":"FahDr0xQw50S","execution":{"iopub.status.busy":"2023-06-24T09:37:55.738002Z","iopub.execute_input":"2023-06-24T09:37:55.738401Z","iopub.status.idle":"2023-06-24T09:37:55.744822Z","shell.execute_reply.started":"2023-06-24T09:37:55.738362Z","shell.execute_reply":"2023-06-24T09:37:55.743813Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Define Dataset\n\nDefine the dataset.  \nThe dataset returns images of a random character, with (`k_shot + q_query`) images,  \nso the size of returned tensor is `[k_shot+q_query, 1, 28, 28]`.  \n","metadata":{"id":"9Hl7ro2mYzsI"}},{"cell_type":"code","source":"# Dataset for train and val\nclass Omniglot(Dataset):\n    def __init__(self, data_dir, k_shot, q_query, task_num=None):\n        self.file_list = [\n            f for f in glob.glob(data_dir + \"**/character*\", recursive=True)\n        ]\n        # limit task number if task_num is set\n        if task_num is not None:\n            self.file_list = self.file_list[: min(len(self.file_list), task_num)]\n        self.transform = transforms.Compose([transforms.ToTensor()])\n        self.n = k_shot + q_query\n\n    def __getitem__(self, idx):\n        # For random sampling the characters we want.\n        img_path = self.file_list[idx]\n        img_list = [f for f in glob.glob(img_path + \"**/*.png\", recursive=True)]\n        img_list.sort()\n\n        sample = np.arange(len(img_list))\n        np.random.shuffle(sample)\n\n        # `k_shot + q_query` examples for each character\n        imgs = [self.transform(Image.open(img_list[idx])) for idx in sample[:self.n]]\n        imgs = torch.stack(imgs)\n        return imgs\n\n    def __len__(self):\n        return len(self.file_list)","metadata":{"id":"-tJ2mot9hHPb","execution":{"iopub.status.busy":"2023-06-24T09:37:55.746651Z","iopub.execute_input":"2023-06-24T09:37:55.747548Z","iopub.status.idle":"2023-06-24T09:37:55.757918Z","shell.execute_reply.started":"2023-06-24T09:37:55.747513Z","shell.execute_reply":"2023-06-24T09:37:55.756903Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **Step 3: Learning Algorithms**\n\n### Transfer learning\n\nThe solver first chose five task from the training set, then do normal classification training on the chosen five tasks. In inference, the model finetune for `inner_train_step` steps on the support set images, and than do inference on the query set images.\n\nFor consistant with the meta-learning solver, the base solver has the exactly same input and output format with the meta-learning solver.\n\n","metadata":{"id":"WRzjBWhwI6tc"}},{"cell_type":"code","source":"def BaseSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False,\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # Get data\n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n\n        if train:\n            \"\"\" training loop \"\"\"\n            # Use the support set to calculate loss\n            labels = create_label(n_way, k_shot).to(device)\n            logits = model.forward(support_set)\n            loss = criterion(logits, labels)\n\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, labels))\n        else:\n            \"\"\" validation / testing loop \"\"\"\n            # First update model with support set images for `inner_train_step` steps\n            fast_weights = OrderedDict(model.named_parameters())\n\n\n            for inner_step in range(inner_train_step):\n                # Simply training\n                train_label = create_label(n_way, k_shot).to(device)\n                logits = model.functional_forward(support_set, fast_weights)\n                loss = criterion(logits, train_label)\n\n                grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n                # Perform SGD\n                fast_weights = OrderedDict(\n                    (name, param - inner_lr * grad)\n                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n                )\n\n            if not return_labels:\n                \"\"\" validation \"\"\"\n                val_label = create_label(n_way, q_query).to(device)\n\n                logits = model.functional_forward(query_set, fast_weights)\n                loss = criterion(logits, val_label)\n                task_loss.append(loss)\n                task_acc.append(calculate_accuracy(logits, val_label))\n            else:\n                \"\"\" testing \"\"\"\n                logits = model.functional_forward(query_set, fast_weights)\n                labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    batch_loss = torch.stack(task_loss).mean()\n    task_acc = np.mean(task_acc)\n\n    if train:\n        # Update model\n        model.train()\n        optimizer.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n\n    return batch_loss, task_acc","metadata":{"id":"R_jGPJHK7KpC","execution":{"iopub.status.busy":"2023-06-24T09:37:55.759682Z","iopub.execute_input":"2023-06-24T09:37:55.760358Z","iopub.status.idle":"2023-06-24T09:37:55.775663Z","shell.execute_reply.started":"2023-06-24T09:37:55.760324Z","shell.execute_reply":"2023-06-24T09:37:55.774633Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Meta Learning\n\nHere is the main Meta Learning algorithm.\n\nPlease finish the TODO blocks for the inner and outer loop update rules.\n\n- For implementing FO-MAML you can refer to [p.25 of the slides](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=25&view=FitW).\n\n- For the original MAML, you can refer to [the slides of meta learning (p.13 ~ p.18)](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=13&view=FitW).\n","metadata":{"id":"Gm5iVp90Ylii"}},{"cell_type":"code","source":"def MetaSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # Get data\n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n\n        # Copy the params for inner loop\n        fast_weights = OrderedDict(model.named_parameters())\n\n        ### ---------- INNER TRAIN LOOP ---------- ###\n        for inner_step in range(inner_train_step):\n            # Simply training\n            train_label = create_label(n_way, k_shot).to(device)\n            logits = model.functional_forward(support_set, fast_weights)\n            loss = criterion(logits, train_label)\n            # Inner gradients update! vvvvvvvvvvvvvvvvvvvv #\n            \"\"\" Inner Loop Update \"\"\"\n            # TODO: Finish the inner loop update rule\n            # task_loss.append(loss)\n            # task_acc.append(calculate_accuracy(logits, labels))\n            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n            fast_weights = OrderedDict(\n                (name, param - inner_lr * grad)\n                for ((name, param), grad) in zip(fast_weights.items(), grads)\n            )               \n            \n            #raise NotImplementedError\n            # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ #\n\n        ### ---------- INNER VALID LOOP ---------- ###\n        if not return_labels:\n            \"\"\" training / validation \"\"\"\n            val_label = create_label(n_way, q_query).to(device)\n\n            # Collect gradients for outer loop\n            logits = model.functional_forward(query_set, fast_weights)\n            loss = criterion(logits, val_label)\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, val_label))\n        else:\n            \"\"\" testing \"\"\"\n            logits = model.functional_forward(query_set, fast_weights)\n            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    # Update outer loop\n    model.train()\n    optimizer.zero_grad()\n\n    meta_batch_loss = torch.stack(task_loss).mean()\n    if train:\n        \"\"\" Outer Loop Update \"\"\"\n        # TODO: Finish the outer loop update\n        meta_batch_loss.backward()\n        optimizer.step()\n        \n        #raise NotimplementedError\n\n    task_acc = np.mean(task_acc)\n    return meta_batch_loss, task_acc","metadata":{"id":"KjNxrWW_yNck","execution":{"iopub.status.busy":"2023-06-24T09:39:47.026937Z","iopub.execute_input":"2023-06-24T09:39:47.027379Z","iopub.status.idle":"2023-06-24T09:39:47.045117Z","shell.execute_reply.started":"2023-06-24T09:39:47.027333Z","shell.execute_reply":"2023-06-24T09:39:47.043994Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## **Step 4: Initialization**\n\nAfter defining all components we need, the following initialize a model before training.","metadata":{"id":"nBoRBhVlZAST"}},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{"id":"Ip-i7aseftUF"}},{"cell_type":"code","source":"n_way = 5\nk_shot = 1\nq_query = 1\ntrain_inner_train_step = 1\nval_inner_train_step = 3\ninner_lr = 0.4\nmeta_lr = 0.001\nmeta_batch_size = 32\nmax_epoch = 100\neval_batches = 20\ntrain_data_path = \"./Omniglot/images_background/\"","metadata":{"id":"0wFHmVcBhE4M","execution":{"iopub.status.busy":"2023-06-24T09:39:49.817160Z","iopub.execute_input":"2023-06-24T09:39:49.817537Z","iopub.status.idle":"2023-06-24T09:39:49.823864Z","shell.execute_reply.started":"2023-06-24T09:39:49.817504Z","shell.execute_reply":"2023-06-24T09:39:49.822594Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader initialization","metadata":{"id":"Uvzo7NVpfu5V"}},{"cell_type":"code","source":"def dataloader_init(datasets, shuffle=True, num_workers=2):\n    train_set, val_set = datasets\n    train_loader = DataLoader(\n        train_set,\n        # The \"batch_size\" here is not \\\n        #    the meta batch size, but  \\\n        #    how many different        \\\n        #    characters in a task,     \\\n        #    i.e. the \"n_way\" in       \\\n        #    few-shot classification.\n        batch_size=n_way,\n        num_workers=num_workers,\n        shuffle=shuffle,\n        drop_last=True,\n    )\n    val_loader = DataLoader(\n        val_set, batch_size=n_way, num_workers=num_workers, shuffle=shuffle, drop_last=True\n    )\n\n    train_iter = iter(train_loader)\n    val_iter = iter(val_loader)\n    return (train_loader, val_loader), (train_iter, val_iter)","metadata":{"id":"3I13GJavhP0_","execution":{"iopub.status.busy":"2023-06-24T09:39:52.748143Z","iopub.execute_input":"2023-06-24T09:39:52.748502Z","iopub.status.idle":"2023-06-24T09:39:52.755252Z","shell.execute_reply.started":"2023-06-24T09:39:52.748472Z","shell.execute_reply":"2023-06-24T09:39:52.754159Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Model & optimizer initialization","metadata":{"id":"KVund--bfw0e"}},{"cell_type":"code","source":"def model_init():\n    meta_model = Classifier(1, n_way).to(device)\n    optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    return meta_model, optimizer, loss_fn","metadata":{"id":"Kxug882ihF2B","execution":{"iopub.status.busy":"2023-06-24T09:39:55.084563Z","iopub.execute_input":"2023-06-24T09:39:55.084954Z","iopub.status.idle":"2023-06-24T09:39:55.091036Z","shell.execute_reply.started":"2023-06-24T09:39:55.084921Z","shell.execute_reply":"2023-06-24T09:39:55.089793Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Utility function to get a meta-batch","metadata":{"id":"gj8cLRNLf2zg"}},{"cell_type":"code","source":"def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n    data = []\n    for _ in range(meta_batch_size):\n        try:\n            # a \"task_data\" tensor is representing \\\n            #     the data of a task, with size of \\\n            #     [n_way, k_shot+q_query, 1, 28, 28]\n            task_data = next(iterator)\n        except StopIteration:\n            iterator = iter(data_loader)\n            task_data = next(iterator)\n        train_data = task_data[:, :k_shot].reshape(-1, 1, 28, 28)\n        val_data = task_data[:, k_shot:].reshape(-1, 1, 28, 28)\n        task_data = torch.cat((train_data, val_data), 0)\n        data.append(task_data)\n    return torch.stack(data).to(device), iterator","metadata":{"id":"zrkCSsxOhC-N","execution":{"iopub.status.busy":"2023-06-24T09:39:56.908819Z","iopub.execute_input":"2023-06-24T09:39:56.909218Z","iopub.status.idle":"2023-06-24T09:39:56.916923Z","shell.execute_reply.started":"2023-06-24T09:39:56.909173Z","shell.execute_reply":"2023-06-24T09:39:56.915786Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"<a name=\"mainprog\" id=\"mainprog\"></a>\n## **Step 5: Main program for training & testing**","metadata":{"id":"pWQczA3FwjEG"}},{"cell_type":"markdown","source":"### Start training!\nWith `solver = 'base'`, the solver is a transfer learning algorithm.\n\nOnce you finish the TODO blocks in the `MetaSolver`, change the variable `solver = 'meta'` to start training with meta learning algorithm.\n","metadata":{"id":"8EirEnaof7ep"}},{"cell_type":"code","source":"solver = 'meta' # base, meta\nmeta_model, optimizer, loss_fn = model_init()\n\n# init solver and dataset according to solver type\nif solver == 'base':\n    max_epoch = 5 # the base solver only needs 5 epochs\n    Solver = BaseSolver\n    train_set, val_set = torch.utils.data.random_split(\n        Omniglot(train_data_path, k_shot, q_query, task_num=10), [5, 5]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set), shuffle=False)\n\nelif solver == 'meta':\n    Solver = MetaSolver\n    dataset = Omniglot(train_data_path, k_shot, q_query)\n    train_split = int(0.8 * len(dataset))\n    val_split = len(dataset) - train_split\n    train_set, val_set = torch.utils.data.random_split(\n        dataset, [train_split, val_split]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set))\nelse:\n    raise NotImplementedError\n\n\n# main training loop\nfor epoch in range(max_epoch):\n    print(\"Epoch %d\" % (epoch + 1))\n    train_meta_loss = []\n    train_acc = []\n    # The \"step\" here is a meta-gradinet update step\n    for step in tqdm(range(max(1, len(train_loader) // meta_batch_size))):\n        x, train_iter = get_meta_batch(\n            meta_batch_size, k_shot, q_query, train_loader, train_iter\n        )\n        meta_loss, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn,\n            inner_train_step=train_inner_train_step\n        )\n        train_meta_loss.append(meta_loss.item())\n        train_acc.append(acc)\n    print(\"  Loss    : \", \"%.3f\" % (np.mean(train_meta_loss)), end=\"\\t\")\n    print(\"  Accuracy: \", \"%.3f %%\" % (np.mean(train_acc) * 100))\n\n    # See the validation accuracy after each epoch.\n    # Early stopping is welcomed to implement.\n    val_acc = []\n    for eval_step in tqdm(range(max(1, len(val_loader) // (eval_batches)))):\n        x, val_iter = get_meta_batch(\n            eval_batches, k_shot, q_query, val_loader, val_iter\n        )\n        # We update three inner steps when testing.\n        _, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn,\n            inner_train_step=val_inner_train_step,\n            train=False,\n        )\n        val_acc.append(acc)\n    print(\"  Validation accuracy: \", \"%.3f %%\" % (np.mean(val_acc) * 100))","metadata":{"id":"JQZjJrLAhBWw","execution":{"iopub.status.busy":"2023-06-24T09:39:59.062214Z","iopub.execute_input":"2023-06-24T09:39:59.062583Z","iopub.status.idle":"2023-06-24T09:41:14.937262Z","shell.execute_reply.started":"2023-06-24T09:39:59.062545Z","shell.execute_reply":"2023-06-24T09:41:14.935795Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eeb1f19254e444ba4c216d45496935c"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  3.012\t  Accuracy:  24.531 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11878639a5bb414baad409a50381b5cd"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  42.000 %\nEpoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6b11c237c64986a1f976bc2f968451"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.520\t  Accuracy:  36.406 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefb44bf9c704099b93e0931f32d8a1c"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  36.000 %\nEpoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3b28b3e2f34a70a3295bbced281c69"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.367\t  Accuracy:  40.312 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8004013d095b476196323ec17e969291"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  35.000 %\nEpoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b87d7ee6bc84fb889fd357a2917edf7"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.285\t  Accuracy:  46.719 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f5faf1119d4147ba7f64af3e84a450"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  47.000 %\nEpoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da2c3b7d06214183a9cee2b9618a40fa"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.246\t  Accuracy:  50.625 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b39b7adf9a423d80dc928cfb668bb1"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  45.000 %\nEpoch 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248eb47344d1442ca647263557cc2df1"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.218\t  Accuracy:  53.906 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8b8a7aafde4518ba7928a7882cb6f0"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  42.000 %\nEpoch 7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689586f4c223401887d13e60e53278a3"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.214\t  Accuracy:  53.438 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd555193df2490cabb19275d276ae76"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  38.000 %\nEpoch 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d09898cd6df476fa8a52a25423801f1"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.180\t  Accuracy:  56.563 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26b09ffe0b4f4f65a12905c985baf36d"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  47.000 %\nEpoch 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f5a37f2e5749969036ba70e0f2eec6"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.116\t  Accuracy:  59.531 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0a33d86e52f4179910c6cbbe5eb8227"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  47.000 %\nEpoch 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1b69e0bb42405389f9eda04e80ae62"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.109\t  Accuracy:  61.250 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30a1ca1d335a4b378d6dd6125c442da5"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  51.000 %\nEpoch 11\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfba79f4d96f440d86927ff4e975a31b"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.068\t  Accuracy:  61.250 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82201fcacae045a388d1d978912f5369"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  47.000 %\nEpoch 12\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca581a891184d2e8f43f1a008ca7203"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.087\t  Accuracy:  58.281 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7dce6a0a3d84be585c0e91c1a7198b4"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  47.000 %\nEpoch 13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a81251772704e0685983a3f8e29e2d4"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.031\t  Accuracy:  63.594 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c7c2b368b041cf843c6f1c532a4c61"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  54.000 %\nEpoch 14\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa7d196123414752851653f93557df95"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  1.003\t  Accuracy:  63.594 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e514c92702684ff386a238a052183026"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  48.000 %\nEpoch 15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16af2bdc96a74b73b69067c5894be58d"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.952\t  Accuracy:  65.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e52a4dbe0a94137bc6d02944a9b5ad2"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  57.000 %\nEpoch 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2af095fc804a9c8f73362c35fc1793"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.952\t  Accuracy:  66.562 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143d644c773442d68d970199bc507ac9"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  54.000 %\nEpoch 17\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebd89c79307444b85254fe444694d2d"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.922\t  Accuracy:  67.031 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6705ba523eda42d884a5980c365cf650"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  66.000 %\nEpoch 18\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a05f02f7174016a2547f700b679065"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.878\t  Accuracy:  69.219 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7980c4847f4c9e82a410c3623b797d"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  55.000 %\nEpoch 19\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17e83403d6d4d979a6ed8583e218926"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.843\t  Accuracy:  69.687 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c60070c839345cd880936a123e9d94f"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  60.000 %\nEpoch 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc0ac5f8b334f7e870b869fb38aeb33"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.845\t  Accuracy:  70.625 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f4e2051752b415e87cbd20172d8a856"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  59.000 %\nEpoch 21\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdefdeb65474542870b572a751c2be7"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.784\t  Accuracy:  74.844 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a6a18f3b3d40029ddc0482c32341b5"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  58.000 %\nEpoch 22\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa29eaf049546df8b1949ebdf596112"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.714\t  Accuracy:  75.312 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a756ec8a40841cdbeef63959ed0f0e8"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  73.000 %\nEpoch 23\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239745f502434ad4af476c5624cda6ad"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.719\t  Accuracy:  76.406 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fd5201a71a43299d0810edbb555501"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  72.000 %\nEpoch 24\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45fe0ea6acf4ab0909bbdc77d41c057"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.642\t  Accuracy:  80.938 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebec113761f4c138529e7c8547bcbac"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  70.000 %\nEpoch 25\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc11cf1d3c22400894476d040280a8cb"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.670\t  Accuracy:  78.750 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4463a00dc23948fb838e478feb24d65a"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  79.000 %\nEpoch 26\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf501d854624bcdb7bae54ed4c14db1"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.619\t  Accuracy:  81.406 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14f3d7156c448a19cd0e4298ca42bd1"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  81.000 %\nEpoch 27\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f590460c515447b8bd6cf9d8c6cd66a7"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.565\t  Accuracy:  82.031 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80c0d42ecfdd46b684c36b830f08e7ec"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  83.000 %\nEpoch 28\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae8f754b4b24ac28467f7060e4ac193"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.574\t  Accuracy:  81.562 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b7f46afee274420afe08b89d8167f86"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  69.000 %\nEpoch 29\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"984d18582cfa47c1bb77f54c35a545cd"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.538\t  Accuracy:  81.719 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc52968c54444b59a5a5c031a5df6f34"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  75.000 %\nEpoch 30\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f83ff1ce3df241199b0d3ee25ae99d93"}},"metadata":{}},{"name":"stdout","text":"  Loss    :  0.545\t  Accuracy:  82.969 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69a8c26ebfcc4cc885c809ff2800ef1a"}},"metadata":{}},{"name":"stdout","text":"  Validation accuracy:  77.000 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Testing the result\n\nSince the testing data is sampled by TAs in advance, you should not change the code in `OmnigloTest` dataset, otherwise your score may not be correct on the Kaggle leaderboard.\n\nHowever, fell free to chagne the variable `inner_train_step` to set the training steps on the query set images.","metadata":{"id":"u5Ew8-POf9sw"}},{"cell_type":"code","source":"import os\n\n# test dataset\nclass OmniglotTest(Dataset):\n    def __init__(self, test_dir):\n        self.test_dir = test_dir\n        self.n = 5\n\n        self.transform = transforms.Compose([transforms.ToTensor()])\n\n    def __getitem__(self, idx):\n        support_files = [\n            os.path.join(self.test_dir, \"support\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n        query_files = [\n            os.path.join(self.test_dir, \"query\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n\n        support_imgs = torch.stack(\n            [self.transform(Image.open(e)) for e in support_files]\n        )\n        query_imgs = torch.stack([self.transform(Image.open(e)) for e in query_files])\n\n        return support_imgs, query_imgs\n\n    def __len__(self):\n        return len(os.listdir(os.path.join(self.test_dir, \"support\")))","metadata":{"id":"OKtTzxZeln5Z","execution":{"iopub.status.busy":"2023-06-24T09:41:32.392244Z","iopub.execute_input":"2023-06-24T09:41:32.393232Z","iopub.status.idle":"2023-06-24T09:41:32.419669Z","shell.execute_reply.started":"2023-06-24T09:41:32.393163Z","shell.execute_reply":"2023-06-24T09:41:32.417631Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_inner_train_step = 10 # you can change this\n\ntest_batches = 20\ntest_dataset = OmniglotTest(\"Omniglot-test\")\ntest_loader = DataLoader(test_dataset, batch_size=test_batches, shuffle=False)\n\noutput = []\nfor _, batch in enumerate(tqdm(test_loader)):\n    support_set, query_set = batch\n    x = torch.cat([support_set, query_set], dim=1)\n    x = x.to(device)\n\n    labels = Solver(\n        meta_model,\n        optimizer,\n        x,\n        n_way,\n        k_shot,\n        q_query,\n        loss_fn,\n        inner_train_step=test_inner_train_step,\n        train=False,\n        return_labels=True,\n    )\n\n    output.extend(labels)","metadata":{"id":"kTWHs1RThgGc","execution":{"iopub.status.busy":"2023-06-24T09:41:35.742440Z","iopub.execute_input":"2023-06-24T09:41:35.742823Z","iopub.status.idle":"2023-06-24T09:41:55.867669Z","shell.execute_reply.started":"2023-06-24T09:41:35.742789Z","shell.execute_reply":"2023-06-24T09:41:55.866756Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"673e5f1ab2b14e469cdc5bce71ddcb83"}},"metadata":{}}]},{"cell_type":"code","source":"# write to csv\nwith open(\"output.csv\", \"w\") as f:\n    f.write(f\"id,class\\n\")\n    for i, label in enumerate(output):\n        f.write(f\"{i},{label}\\n\")","metadata":{"id":"kYOd98juJL6q","execution":{"iopub.status.busy":"2023-06-24T09:41:58.017184Z","iopub.execute_input":"2023-06-24T09:41:58.017543Z","iopub.status.idle":"2023-06-24T09:41:58.029536Z","shell.execute_reply.started":"2023-06-24T09:41:58.017513Z","shell.execute_reply":"2023-06-24T09:41:58.028563Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Download the `output.csv` and submit to Kaggle!","metadata":{"id":"yIfamxgMIaXw"}},{"cell_type":"markdown","source":"## **Reference**\n1. Chelsea Finn, Pieter Abbeel, & Sergey Levine. (2017). [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.](https://arxiv.org/abs/1909.09157)\n1. Aniruddh Raghu, Maithra Raghu, Samy Bengio, & Oriol Vinyals. (2020). [Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML.](https://arxiv.org/abs/1909.09157)","metadata":{"id":"rtD8X3RLf-6w"}}]}